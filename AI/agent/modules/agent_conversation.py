"""
Agent ëŒ€í™” ì‹œìŠ¤í…œ ëª¨ë“ˆ

ë‘ Agent ê°„ì˜ ëŒ€í™”ë¥¼ ì²˜ë¦¬í•˜ê³  ë©”ëª¨ë¦¬ì— ì €ì¥í•˜ëŠ” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
"""

import json
import os
import uuid
import re
from datetime import datetime
from pathlib import Path
import asyncio

class AgentConversationManager:
    def __init__(self, ollama_client, memory_utils, word2vec_model, max_turns=10):
        """
        Agent ëŒ€í™” ê´€ë¦¬ì ì´ˆê¸°í™”
        
        Args:
            ollama_client: OllamaClient ì¸ìŠ¤í„´ìŠ¤
            memory_utils: MemoryUtils ì¸ìŠ¤í„´ìŠ¤
            word2vec_model: Word2Vec ëª¨ë¸
            max_turns: ìµœëŒ€ ëŒ€í™” í„´ ìˆ˜ (ê¸°ë³¸ê°’: 10)
        """
        self.ollama_client = ollama_client
        self.memory_utils = memory_utils
        self.word2vec_model = word2vec_model
        self.max_turns = max_turns  # ëª¨ë“ˆ ë‚´ë¶€ì—ì„œ ìµœëŒ€ í„´ ìˆ˜ ì„¤ì •
        
        # í˜„ì¬ íŒŒì¼ì˜ ì ˆëŒ€ ê²½ë¡œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ìƒìœ„ ë””ë ‰í† ë¦¬ ì°¾ê¸°
        current_dir = Path(__file__).parent
        root_dir = current_dir.parent.parent  # AI ë””ë ‰í† ë¦¬
        agent_dir = root_dir / "agent"
        
        # ëŒ€í™” ì €ì¥ ë””ë ‰í† ë¦¬
        self.conversations_dir = agent_dir / "data" / "conversations"
        os.makedirs(self.conversations_dir, exist_ok=True)
        
        print(f"âœ… AgentConversationManager ì´ˆê¸°í™” ì™„ë£Œ (ìµœëŒ€ ëŒ€í™” í„´ ìˆ˜: {self.max_turns})")
    
    async def process_conversation(self, payload):
        """
        ëŒ€í™” ì²˜ë¦¬ í•µì‹¬ ë¡œì§
        
        Args:
            payload: ëŒ€í™” ìš”ì²­ ë°ì´í„°
            
        Returns:
            dict: ì²˜ë¦¬ ê²°ê³¼
        """
        try:
            # ê¸°ë³¸ ê²€ì¦
            if "agents" not in payload or len(payload.get("agents", [])) < 2:
                return {"success": False, "error": "At least two agents are required"}
            
            # ëŒ€í™” ID í™•ì¸
            conversation_id = payload.get("conversation_id")
            is_new_conversation = not conversation_id
            
            # ì—ì´ì „íŠ¸ ì •ë³´ ì¶”ì¶œ
            agents = payload.get("agents", [])
            current_speaker_name = payload.get("current_speaker")
            location = payload.get("location", "")
            context = payload.get("context", "")
            
            # í™”ì ì •ë³´ ì¶”ì¶œ
            current_speaker = next((a for a in agents if a["name"] == current_speaker_name), None)
            other_agent = next((a for a in agents if a["name"] != current_speaker_name), None)
            
            if not current_speaker or not other_agent:
                return {"success": False, "error": "Invalid speaker configuration"}
            
            # 1. ìƒˆ ëŒ€í™” ë˜ëŠ” ê¸°ì¡´ ëŒ€í™” ë¡œë“œ
            if is_new_conversation:
                conversation = self._initialize_conversation(agents, location, context)
                conversation_id = conversation["conversation_id"]
            else:
                conversation = await self._load_conversation(conversation_id)
                if not conversation:
                    return {"success": False, "error": f"Conversation {conversation_id} not found"}
            
            # 2. ëŒ€í™” í„´ ìˆ˜ í™•ì¸ - ìµœëŒ€ í„´ ìˆ˜ì— ë„ë‹¬í–ˆëŠ”ì§€ ì²´í¬
            current_turns = len(conversation["messages"])
            force_end = False
            
            if current_turns >= self.max_turns - 1:  # ì´ë²ˆ í„´ì´ ë§ˆì§€ë§‰ í„´ì´ ë  ê²½ìš°
                print(f"ğŸ”š ìµœëŒ€ ëŒ€í™” í„´ ìˆ˜({self.max_turns})ì— ë„ë‹¬í•˜ì—¬ ëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                force_end = True
            
            # 3. ì´ì „ ëŒ€í™” ë©”ëª¨ë¦¬ ë¡œë“œ
            previous_conversations = await self._get_previous_conversations(
                current_speaker["name"], 
                other_agent["name"]
            )
            
            # 4. í”„ë¡¬í”„íŠ¸ ìƒì„± - ê°•ì œ ì¢…ë£Œ íŒíŠ¸ í¬í•¨
            prompt = self._create_conversation_prompt(
                conversation=conversation,
                current_speaker=current_speaker,
                other_agent=other_agent,
                previous_conversations=previous_conversations,
                location=location,
                context=context,
                force_end=force_end,
                current_turns=current_turns,
                max_turns=self.max_turns
            )
            
            # 5. ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±
            system_prompt = self._get_system_prompt(force_end)
            
            # 6. Gemma ëª¨ë¸ í˜¸ì¶œ
            response = await self.ollama_client.process_prompt(
                prompt=prompt,
                system_prompt=system_prompt,
                model_name="gemma3"
            )
            
            # 7. ì‘ë‹µ íŒŒì‹±
            parsed_response = self._parse_conversation_response(
                response.get("response", ""),
                default_next_speaker=other_agent["name"]
            )
            
            # 8. ê°•ì œ ì¢…ë£Œ ì ìš©
            if force_end:
                parsed_response["should_continue"] = False
                if not parsed_response.get("reason_to_end"):
                    parsed_response["reason_to_end"] = f"Conversation naturally concluded after {current_turns + 1} exchanges"
            
            # 9. ëŒ€í™” ì—…ë°ì´íŠ¸
            new_message = {
                "speaker": current_speaker["name"],
                "message": parsed_response["message"],
                "emotion": parsed_response["emotion"],
                "time": current_speaker["time"]
            }
            
            conversation["messages"].append(new_message)
            conversation["last_updated"] = current_speaker["time"]
            
            # 10. ëŒ€í™” ì €ì¥
            await self._save_conversation(conversation)
            
            # 11. ëŒ€í™” ì¢…ë£Œ ì²˜ë¦¬
            memory_ids = []
            if not parsed_response["should_continue"]:
                # ëŒ€í™” ì¢…ë£Œ ì²˜ë¦¬
                conversation["status"] = "completed"
                
                # ì¢…ë£Œ ì´ìœ  (ê°•ì œ ì¢…ë£Œ ì—¬ë¶€ì— ë”°ë¼ ë‹¤ë¦„)
                if force_end and not parsed_response.get("reason_to_end"):
                    conversation["end_reason"] = f"Conversation reached the maximum of {self.max_turns} turns"
                else:
                    conversation["end_reason"] = parsed_response.get("reason_to_end", "Natural conclusion")
                
                # ëŒ€í™” ë©”ëª¨ë¦¬ì— ì €ì¥
                memory_ids = await self._save_conversation_to_memory(
                    conversation, 
                    agents,
                    parsed_response.get("importance", 3)
                )
                
                # ëŒ€í™” ì €ì¥ (ìƒíƒœ ì—…ë°ì´íŠ¸)
                await self._save_conversation(conversation)
            
            # 12. ì‘ë‹µ êµ¬ì„±
            result = {
                "success": True,
                "conversation_id": conversation_id,
                "message": new_message,
                "should_continue": parsed_response["should_continue"],
                "next_speaker": parsed_response["next_speaker"],
                "turns": current_turns + 1,
                "max_turns": self.max_turns
            }
            
            if memory_ids:
                result["memory_ids"] = memory_ids
            
            if not parsed_response["should_continue"]:
                result["conversation"] = conversation
            
            return result
            
        except Exception as e:
            print(f"Error processing conversation: {e}")
            return {"success": False, "error": str(e)}
    
    def _initialize_conversation(self, agents, location, context):
        """ìƒˆ ëŒ€í™” ì´ˆê¸°í™”"""
        conversation_id = f"conv_{uuid.uuid4().hex[:8]}"
        
        return {
            "conversation_id": conversation_id,
            "agents": [a["name"] for a in agents],
            "location": location,
            "context": context,
            "messages": [],
            "status": "active",
            "start_time": agents[0]["time"],  # ì²« ë²ˆì§¸ ì—ì´ì „íŠ¸ì˜ ì‹œê°„ ì‚¬ìš©
            "last_updated": agents[0]["time"],
            "end_reason": ""
        }
    
    async def _load_conversation(self, conversation_id):
        """ëŒ€í™” ë¡œë“œ"""
        filepath = self.conversations_dir / f"{conversation_id}.json"
        
        if not os.path.exists(filepath):
            return None
        
        # íŒŒì¼ ë¡œë“œ
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"Error loading conversation {conversation_id}: {e}")
            return None
    
    async def _save_conversation(self, conversation):
        """ëŒ€í™” ì €ì¥"""
        filepath = self.conversations_dir / f"{conversation['conversation_id']}.json"
        
        try:
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(conversation, f, ensure_ascii=False, indent=2)
            return True
        except Exception as e:
            print(f"Error saving conversation: {e}")
            return False
    
    async def _get_previous_conversations(self, agent1_name, agent2_name, max_count=3):
        """ì´ì „ ëŒ€í™” ë©”ëª¨ë¦¬ ì¡°íšŒ"""
        # ë©”ëª¨ë¦¬ì—ì„œ ë‘ ì—ì´ì „íŠ¸ ê°„ì˜ ì´ì „ ëŒ€í™” ê²€ìƒ‰
        memories = self.memory_utils._load_memories()
        
        if agent1_name not in memories:
            return []
        
        conversation_memories = []
        for memory in memories[agent1_name]["memories"]:
            if memory.get("event_type") == "conversation":
                details = memory.get("details", {})
                if details.get("with") == agent2_name:
                    conversation_memories.append({
                        "time": memory.get("time", ""),
                        "summary": details.get("summary", ""),
                        "importance": memory.get("importance", 5),
                        "location": details.get("location", "")
                    })
        
        # ìµœê·¼ ëŒ€í™” ìˆœìœ¼ë¡œ ì •ë ¬
        conversation_memories.sort(key=lambda x: x["time"], reverse=True)
        return conversation_memories[:max_count]
    
    async def _save_conversation_to_memory(self, conversation, agents, importance=5):
        """ëŒ€í™”ë¥¼ ë©”ëª¨ë¦¬ì— ì €ì¥"""
        memory_ids = []
        
        # ëŒ€í™” ìš”ì•½ ìƒì„±
        summaries = await self._generate_conversation_summaries(conversation, agents)
        
        # ê° ì—ì´ì „íŠ¸ì— ëŒ€í•´ ë©”ëª¨ë¦¬ ì €ì¥
        for agent in agents:
            agent_name = agent["name"]
            other_agent = next(a for a in agents if a["name"] != agent_name)
            
            # ì´ë²¤íŠ¸ ë¬¸ì¥ ìƒì„±
            event_sentence = f"Conversation with {other_agent['name']} at {conversation['location']}"
            
            # ì„ë² ë”© ìƒì„±
            embedding = self.memory_utils.get_embedding(event_sentence)
            
            # ë©”ëª¨ë¦¬ ì €ì¥
            memory = {
                "event": event_sentence,
                "time": agent["time"],
                "embeddings": embedding,
                "event_type": "conversation",
                "importance": summaries.get("importance", importance),
                "details": {
                    "conversation_id": conversation["conversation_id"],
                    "with": other_agent["name"],
                    "location": conversation["location"],
                    "summary": summaries.get(f"{agent_name.lower()}_memory", 
                                          f"Talked with {other_agent['name']} about various topics")
                }
            }
            
            # ë©”ëª¨ë¦¬ì— ì €ì¥
            memories = self.memory_utils._load_memories()
            
            if agent_name not in memories:
                memories[agent_name] = {"memories": []}
            
            # ë©”ëª¨ë¦¬ ID ìƒì„±
            memory_id = 1
            if memories[agent_name]["memories"]:
                memory_id = max([m.get("event_id", 0) for m in memories[agent_name]["memories"]]) + 1
            
            memory["event_id"] = memory_id
            memories[agent_name]["memories"].append(memory)
            
            # ì €ì¥
            self.memory_utils._save_memories(memories)
            memory_ids.append(memory_id)
        
        return memory_ids
    
    async def _generate_conversation_summaries(self, conversation, agents):
        """ëŒ€í™” ìš”ì•½ ìƒì„±"""
        if not conversation["messages"]:
            return {
                "importance": 3,
                f"{agents[0]['name'].lower()}_memory": f"Brief encounter with {agents[1]['name']}",
                f"{agents[1]['name'].lower()}_memory": f"Brief encounter with {agents[0]['name']}"
            }
        
        # ëŒ€í™” ì „ì²´ ë‚´ìš© í¬ë§·íŒ…
        conversation_text = "\n".join([f"{msg['speaker']}: {msg['message']}" for msg in conversation["messages"]])
        
        # ìš”ì•½ ìƒì„± í”„ë¡¬í”„íŠ¸
        prompt = f"""
Summarize the following conversation between {agents[0]['name']} and {agents[1]['name']}:

{conversation_text}

Create three items:
1. A summary from {agents[0]['name']}'s perspective (what they would remember)
2. A summary from {agents[1]['name']}'s perspective (what they would remember)
3. An importance rating (1-10) indicating how memorable/significant this conversation is

Format your response as JSON:
{{
  "{agents[0]['name'].lower()}_memory": "Summary from {agents[0]['name']}'s perspective",
  "{agents[1]['name'].lower()}_memory": "Summary from {agents[1]['name']}'s perspective",
  "importance": 1-10
}}
"""
        
        # Gemma ëª¨ë¸ í˜¸ì¶œ
        system_prompt = "You are an AI that summarizes conversations. Respond only with the requested JSON format."
        response = await self.ollama_client.process_prompt(
            prompt=prompt,
            system_prompt=system_prompt,
            model_name="gemma3"
        )
        
        # JSON íŒŒì‹±
        try:
            json_pattern = r'\{(?:[^{}]|(?:\{(?:[^{}]|(?:\{[^{}]*\}))*\}))*\}'
            matches = re.findall(json_pattern, response.get("response", ""))
            
            if matches:
                for match in matches:
                    try:
                        return json.loads(match)
                    except:
                        continue
            
            # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
            return {
                "importance": 5,
                f"{agents[0]['name'].lower()}_memory": f"Talked with {agents[1]['name']} at {conversation['location']}",
                f"{agents[1]['name'].lower()}_memory": f"Talked with {agents[0]['name']} at {conversation['location']}"
            }
            
        except Exception as e:
            print(f"Error parsing summary response: {e}")
            return {
                "importance": 4,
                f"{agents[0]['name'].lower()}_memory": f"Had a conversation with {agents[1]['name']}",
                f"{agents[1]['name'].lower()}_memory": f"Had a conversation with {agents[0]['name']}"
            }
    
    def _get_system_prompt(self, force_end=False):
        """ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        base_prompt = """
You are an AI handling a conversation between two game characters. Your task is to generate a natural response for the current speaker and determine if the conversation should continue.

Respond in this exact JSON format:
{
  "message": "Your natural dialogue response here",
  "emotion": "one word describing the emotional state (e.g., happy, curious, concerned)",
  "should_continue": true/false,
  "reason_to_end": "Only provide if should_continue is false, explaining why conversation would naturally end",
  "next_speaker": "Name of the other participant",
  "importance": 1-10 (how memorable/significant this conversation is)
}

Make dialogue natural and reflect the speaker's personality and current state.
"""

        # ê°•ì œ ì¢…ë£Œê°€ í•„ìš”í•œ ê²½ìš° ì¶”ê°€ ì§€ì¹¨
        if force_end:
            base_prompt += """

IMPORTANT: This conversation has reached its maximum allowed length. You MUST set "should_continue" to false and provide a natural reason to end the conversation in "reason_to_end" field. Make the ending feel natural based on the context.
"""
        
        return base_prompt
    
    def _create_conversation_prompt(self, conversation, current_speaker, other_agent, previous_conversations, location, context, force_end=False, current_turns=0, max_turns=10):
        """ëŒ€í™” í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        # ëŒ€í™” ê¸°ë¡ í¬ë§·íŒ…
        conversation_history = self._format_conversation_history(conversation["messages"])
        
        # ì´ì „ ëŒ€í™” ë©”ëª¨ë¦¬ í¬ë§·íŒ…
        previous_conversations_text = self._format_previous_conversations(previous_conversations)
        
        # ì—ì´ì „íŠ¸ ìƒíƒœ ì •ë³´ í¬ë§·íŒ…
        current_state = self._format_agent_state(current_speaker.get("state", {}))
        
        # ê¸°ë³¸ í”„ë¡¬í”„íŠ¸
        prompt = f"""
You are {current_speaker["name"]} with personality: {current_speaker["personality"]}
You are talking with {other_agent["name"]} who has personality: {other_agent["personality"]}
Location: {location}
Context: {context}

Your current state:
{current_state}

Previous interactions with {other_agent["name"]}:
{previous_conversations_text}

Current conversation:
{conversation_history}
"""

        # ëŒ€í™” í„´ ìˆ˜ì— ê´€í•œ ì •ë³´ ì¶”ê°€
        if current_turns > 0:
            prompt += f"\nThis is turn {current_turns + 1} of a conversation (maximum {max_turns} turns).\n"
        
        # ê°•ì œ ì¢…ë£Œ í•„ìš”í•œ ê²½ìš° ì•ˆë‚´ë¬¸ ì¶”ê°€
        if force_end:
            prompt += f"""
IMPORTANT: This conversation needs to end naturally after this response. 
Find a natural way to conclude the conversation based on your personality, state, or the context.
Examples of natural endings:
- You need to go somewhere else
- You've shared what you wanted to say
- You need to attend to your needs (like your hunger if it's high)
- The topic has reached its natural conclusion
"""
        else:
            prompt += """
Generate your next response as yourself and decide if the conversation should naturally continue or end.
Consider your personality, current state, conversation context, and history with the other person.

Base your decision to continue or end the conversation on:
1. Natural conversation flow
2. Your current state (hunger, sleepiness, etc.)
3. Your personality traits
4. Previous history with the other person
5. Current location and context

End the conversation only if it would logically conclude (e.g., you need to leave, conversation reached a natural end, etc.)
"""
        
        return prompt
    
    def _format_conversation_history(self, messages):
        """ëŒ€í™” ê¸°ë¡ í¬ë§·íŒ…"""
        if not messages:
            return "No messages yet."
        
        formatted = []
        for msg in messages:
            formatted.append(f"{msg['speaker']}: {msg['message']} ({msg['emotion']})")
        
        return "\n".join(formatted)
    
    def _format_previous_conversations(self, previous_conversations):
        """ì´ì „ ëŒ€í™” ë©”ëª¨ë¦¬ í¬ë§·íŒ…"""
        if not previous_conversations:
            return "No previous interactions."
        
        formatted = []
        for conv in previous_conversations:
            formatted.append(f"- {conv['summary']} ({conv['time']})")
        
        return "\n".join(formatted)
    
    def _format_agent_state(self, state):
        """ì—ì´ì „íŠ¸ ìƒíƒœ í¬ë§·íŒ…"""
        if not state:
            return "No specific state information."
        
        formatted = []
        for key, value in state.items():
            level = "high" if value > 7 else "moderate" if value > 3 else "low"
            formatted.append(f"- {key}: {level} ({value}/10)")
        
        return "\n".join(formatted)
    
    def _parse_conversation_response(self, response, default_next_speaker=None):
        """Gemma ì‘ë‹µ íŒŒì‹±"""
        try:
            # 1. ì „ì²´ ì‘ë‹µì´ ìœ íš¨í•œ JSONì¸ì§€ ì‹œë„
            try:
                result = json.loads(response)
                if "message" in result:
                    return self._validate_response(result, default_next_speaker)
            except json.JSONDecodeError:
                pass
            
            # 2. JSON íŒ¨í„´ ì°¾ê¸°
            json_pattern = r'\{(?:[^{}]|(?:\{(?:[^{}]|(?:\{[^{}]*\}))*\}))*\}'
            matches = re.findall(json_pattern, response)
            
            if matches:
                for match in matches:
                    try:
                        result = json.loads(match)
                        if "message" in result:
                            return self._validate_response(result, default_next_speaker)
                    except json.JSONDecodeError:
                        continue
            
            # 3. ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ì—ì„œ JSON ì¶”ì¶œ
            md_pattern = r'```(?:json)?\s*([\s\S]*?)\s*```'
            md_matches = re.findall(md_pattern, response)
            
            if md_matches:
                for md_match in md_matches:
                    try:
                        result = json.loads(md_match)
                        if "message" in result:
                            return self._validate_response(result, default_next_speaker)
                    except json.JSONDecodeError:
                        continue
            
            # 4. êµ¬ì¡°í™”ëœ JSONì´ ì—†ìœ¼ë©´ ì‘ë‹µì—ì„œ ë©”ì‹œì§€ ì¶”ì¶œ
            message = response.strip()
            if '"message":' in response:
                message_match = re.search(r'"message"\s*:\s*"([^"]*)"', response)
                if message_match:
                    message = message_match.group(1)
            
            # 5. should_continue ê°’ ì¶”ì¶œ ì‹œë„
            should_continue = True
            if '"should_continue"' in response:
                if '"should_continue"\s*:\s*false' in response.lower():
                    should_continue = False
            
            # ê¸°ë³¸ ì‘ë‹µ ë°˜í™˜
            return {
                "message": message,
                "emotion": "neutral",
                "should_continue": should_continue,
                "next_speaker": default_next_speaker,
                "reason_to_end": "",
                "importance": 5
            }
            
        except Exception as e:
            print(f"Error parsing response: {e}")
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ê¸°ë³¸ ì‘ë‹µ ë°˜í™˜
            return {
                "message": "I'm not sure how to respond to that.",
                "emotion": "confused",
                "should_continue": True,
                "next_speaker": default_next_speaker,
                "reason_to_end": "",
                "importance": 3
            }
    
    def _validate_response(self, result, default_next_speaker):
        """ì‘ë‹µ ìœ íš¨ì„± ê²€ì‚¬ ë° ê¸°ë³¸ê°’ ì„¤ì •"""
        # í•„ìˆ˜ í•„ë“œ í™•ì¸ ë° ê¸°ë³¸ê°’ ì„¤ì •
        if "message" not in result:
            result["message"] = "I'm not sure what to say."
        
        if "emotion" not in result:
            result["emotion"] = "neutral"
        
        if "should_continue" not in result:
            result["should_continue"] = True
        
        if "next_speaker" not in result:
            result["next_speaker"] = default_next_speaker
        
        return result